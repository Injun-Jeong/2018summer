이전 까지는 class가 2종류 였지만 이제 2개 이상의 class에 대하여 분류함
-> multinomial classification



만약 class가 3개 라면, 3개의 hypothesis model을 생성함
- 개별적으로 3개의  hypothesis를 만드는 것이 아니라 W를 원소로 하는 행렬을 통해 하나의 hypothesis식을 만듦
- 위와 같은 식을 사용하면 하나의 data에 대하여 3개의 값이 return되는데 그 중 가장 큰 값(확률이 가장 크다고 봄)의 class로 분류함
  - one-hot encoding을 통해 가장 큰 값을 1로 나머지는 0으로 처리
- 앞서 배운 sigmoid 처럼 반환 값을 0과 1사이로 표현하기 위하여 softmax라는 함수를 사용함
  (m.t.) softmax를 통하여 일종의 normalization을 하게 됨
- softmax S(y_i) = e^(y_i) / sum_j {e^(y_j)}



Cost function
- cross-entropy
참고: https://taeoh-kim.github.io/blog/cross-entropy%EC%9D%98-%EC%A0%95%ED%99%95%ED%95%9C-%ED%99%95%EB%A5%A0%EC%A0%81-%EC%9D%98%EB%AF%B8/

****************************** cross-entropy에 대한 자세한 용어 정리 필요














