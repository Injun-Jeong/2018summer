데이터들이 굉장히 크거나 또는 데이터의 형태가 들쑥날쑥할 때는 normalize 하는 것이 좋음


한번에 다 할 수 없어서
 batch size를 설정하여 나누어 학습시킬 것

one epoch이란
: one forward pass and one backward pass of all the training examples
: '모든 training 예시들이 1번 학습 되는 것을' 1-epoch라 부름
ex) 15 epoch: 모든 training examples을 반복 15번 학습 시킬 것임

ex) if you have 1000 training examples, and you batch size is 500, then it will take 2 iterations to complete 1 epoch


그래서 앞으로 "epoch을 얼마로 할거냐?, batch size를 얼마로 할거냐?" 라는 이야기를 들을 건데, 위와 같은 정의를 바탕으로 답변하면 될 것이다.