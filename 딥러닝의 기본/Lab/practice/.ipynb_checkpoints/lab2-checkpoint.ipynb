{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# x and y data\n",
    "x_train = [1, 2, 3]\n",
    "y_train = [1, 2, 3]\n",
    "\n",
    "# 주어진 x와 y에 대하여 W, b의 값을 정의하여야 하는데, 이를 tensorflow에서는 Varialbe이란 node로 정의할 수 있음\n",
    "# 여기서 variable이란 개념은 tensorflow를 실행시키면 tensorflow가 자체적으로 변경시키는 값이다 라는 의미\n",
    "# trainable이라고도 불림\n",
    "# W와 b의 값을 모르니, random_normal로 설정하면서 shape을 값이 하나인 1차원 array(tensor)인 [1]로 정의\n",
    "W = tf.Variable(tf.random_normal([1]), name = 'weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name = 'bias')\n",
    "\n",
    "# our hypothesis xW+b\n",
    "hypothesis = x_train * W + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cost/loss function\n",
    "# tf.square: 제곱\n",
    "# tf.reduce_mean: 평균을 구함\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# minimize cost\n",
    "# tensorflow에는 위와 같은 minimize cost하는데 여러가지 방법이 있는데 그 중에 하나인 gradient descent를 사용할 것임\n",
    "# gradient descent를 사용할 땐, tf.train.GradientDescentOptimizer\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.01)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "# 여기까지 graph를 build 했음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.31653845 [1.0968813] [0.36326635]\n",
      "20 0.012180063 [0.90784895] [0.2650415]\n",
      "40 0.008566014 [0.89461374] [0.24485822]\n",
      "60 0.007757152 [0.89789385] [0.23261498]\n",
      "80 0.0070449566 [0.9025332] [0.22161286]\n",
      "100 0.0063983537 [0.9070986] [0.21119122]\n",
      "120 0.005811092 [0.9114632] [0.2012654]\n",
      "140 0.005277723 [0.91562396] [0.19180658]\n",
      "160 0.004793314 [0.9195893] [0.1827924]\n",
      "180 0.00435337 [0.92336833] [0.17420183]\n",
      "200 0.0039537973 [0.92696977] [0.16601498]\n",
      "220 0.0035908942 [0.9304019] [0.15821292]\n",
      "240 0.0032613091 [0.9336727] [0.15077749]\n",
      "260 0.002961981 [0.9367899] [0.14369151]\n",
      "280 0.0026901122 [0.93976057] [0.13693851]\n",
      "300 0.0024432018 [0.9425916] [0.13050288]\n",
      "320 0.0022189587 [0.94528955] [0.12436971]\n",
      "340 0.0020152915 [0.9478607] [0.11852479]\n",
      "360 0.0018303151 [0.9503112] [0.1129545]\n",
      "380 0.0016623187 [0.9526464] [0.10764601]\n",
      "400 0.0015097439 [0.9548718] [0.10258704]\n",
      "420 0.0013711752 [0.9569926] [0.09776581]\n",
      "440 0.0012453259 [0.95901376] [0.0931712]\n",
      "460 0.0011310236 [0.96094] [0.08879254]\n",
      "480 0.001027217 [0.9627757] [0.08461961]\n",
      "500 0.00093293696 [0.9645251] [0.0806428]\n",
      "520 0.0008473071 [0.96619225] [0.0768529]\n",
      "540 0.0007695358 [0.9677811] [0.07324111]\n",
      "560 0.000698907 [0.9692952] [0.06979908]\n",
      "580 0.0006347559 [0.97073835] [0.06651877]\n",
      "600 0.0005764985 [0.9721135] [0.06339261]\n",
      "620 0.00052358425 [0.973424] [0.06041337]\n",
      "640 0.00047552722 [0.974673] [0.0575742]\n",
      "660 0.00043187934 [0.9758633] [0.05486842]\n",
      "680 0.0003922428 [0.9769976] [0.0522898]\n",
      "700 0.00035623982 [0.9780786] [0.0498324]\n",
      "720 0.00032354254 [0.9791089] [0.04749047]\n",
      "740 0.00029384778 [0.9800908] [0.04525856]\n",
      "760 0.00026687424 [0.9810264] [0.04313153]\n",
      "780 0.00024237932 [0.9819181] [0.04110449]\n",
      "800 0.00022013509 [0.9827678] [0.03917274]\n",
      "820 0.00019992965 [0.9835777] [0.03733178]\n",
      "840 0.00018157886 [0.9843495] [0.0355773]\n",
      "860 0.00016491259 [0.985085] [0.03390527]\n",
      "880 0.00014977537 [0.98578596] [0.03231185]\n",
      "900 0.00013602956 [0.986454] [0.0307933]\n",
      "920 0.00012354415 [0.9870905] [0.02934614]\n",
      "940 0.00011220394 [0.98769724] [0.027967]\n",
      "960 0.000101907615 [0.9882754] [0.02665267]\n",
      "980 9.255284e-05 [0.98882645] [0.02540009]\n",
      "1000 8.405705e-05 [0.9893516] [0.02420639]\n",
      "1020 7.634459e-05 [0.98985183] [0.02306885]\n",
      "1040 6.933629e-05 [0.990329] [0.02198469]\n",
      "1060 6.297224e-05 [0.99078345] [0.02095145]\n",
      "1080 5.719189e-05 [0.9912166] [0.01996679]\n",
      "1100 5.194277e-05 [0.99162936] [0.01902843]\n",
      "1120 4.7175068e-05 [0.99202275] [0.01813414]\n",
      "1140 4.284534e-05 [0.99239767] [0.01728191]\n",
      "1160 3.891274e-05 [0.99275494] [0.01646973]\n",
      "1180 3.534084e-05 [0.99309546] [0.0156957]\n",
      "1200 3.2097007e-05 [0.99341995] [0.01495806]\n",
      "1220 2.9151503e-05 [0.9937292] [0.01425509]\n",
      "1240 2.6475745e-05 [0.9940239] [0.01358515]\n",
      "1260 2.4045672e-05 [0.9943047] [0.01294668]\n",
      "1280 2.1838952e-05 [0.9945724] [0.01233824]\n",
      "1300 1.9833988e-05 [0.9948275] [0.01175838]\n",
      "1320 1.8013847e-05 [0.99507064] [0.01120574]\n",
      "1340 1.6360153e-05 [0.99530226] [0.01067909]\n",
      "1360 1.48585705e-05 [0.99552304] [0.01017721]\n",
      "1380 1.349509e-05 [0.99573344] [0.00969891]\n",
      "1400 1.2256377e-05 [0.99593395] [0.00924309]\n",
      "1420 1.11312065e-05 [0.99612504] [0.0088087]\n",
      "1440 1.0109558e-05 [0.99630713] [0.00839472]\n",
      "1460 9.181936e-06 [0.99648064] [0.00800022]\n",
      "1480 8.339079e-06 [0.99664617] [0.00762423]\n",
      "1500 7.5736552e-06 [0.99680376] [0.00726591]\n",
      "1520 6.878663e-06 [0.9969539] [0.00692443]\n",
      "1540 6.2471154e-06 [0.9970971] [0.006599]\n",
      "1560 5.673645e-06 [0.9972335] [0.00628886]\n",
      "1580 5.152973e-06 [0.99736357] [0.00599331]\n",
      "1600 4.680059e-06 [0.9974875] [0.00571163]\n",
      "1620 4.2504685e-06 [0.99760556] [0.00544319]\n",
      "1640 3.8603303e-06 [0.9977181] [0.00518736]\n",
      "1660 3.5058572e-06 [0.9978253] [0.00494357]\n",
      "1680 3.1843374e-06 [0.99792755] [0.00471122]\n",
      "1700 2.8917357e-06 [0.99802494] [0.0044898]\n",
      "1720 2.6263544e-06 [0.9981177] [0.00427881]\n",
      "1740 2.3853959e-06 [0.9982062] [0.00407774]\n",
      "1760 2.1664916e-06 [0.9982905] [0.00388611]\n",
      "1780 1.9674806e-06 [0.9983708] [0.00370347]\n",
      "1800 1.7870865e-06 [0.99844736] [0.00352943]\n",
      "1820 1.6230334e-06 [0.9985204] [0.00336356]\n",
      "1840 1.4741637e-06 [0.9985899] [0.00320549]\n",
      "1860 1.3388361e-06 [0.9986561] [0.00305487]\n",
      "1880 1.2159754e-06 [0.9987193] [0.00291134]\n",
      "1900 1.1044177e-06 [0.9987795] [0.00277452]\n",
      "1920 1.003062e-06 [0.99883676] [0.00264415]\n",
      "1940 9.1095256e-07 [0.9988915] [0.00251991]\n",
      "1960 8.272886e-07 [0.99894357] [0.0024015]\n",
      "1980 7.514175e-07 [0.9989932] [0.00228865]\n",
      "2000 6.8251893e-07 [0.99904054] [0.00218109]\n"
     ]
    }
   ],
   "source": [
    "# 구현한 graph를 실행하기 위해선 session을 만들어야 함\n",
    "# 그리고 우리가 tf.Variable을 만들었는데, variable을 사용하기 위해서는\n",
    "# 반드시, sess.run(tf.global_variables_initializer()) 을 명령해주어야 함\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(2001):\n",
    "    sess.run(train)\n",
    "    if step % 20 == 0:\n",
    "        print(step, sess.run(cost), sess.run(W), sess.run(b))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
