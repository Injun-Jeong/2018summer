{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'unicode' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-3be156cb16e0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    162\u001b[0m     \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m60\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 164\u001b[1;33m         \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0municode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manimals\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manimals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    165\u001b[0m     \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'unicode' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# coding: utf-8\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from __future__ import print_function\n",
    "import math\n",
    "import os\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import operator\n",
    "\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "class doc_processor(object):\n",
    "    \n",
    "    def __init__(self, name):\n",
    "        \n",
    "        self.name = name\n",
    "        self.word2idx = {}\n",
    "        self.idx2word = {}\n",
    "        self.word2count = {}\n",
    "        self.n_words = 0\n",
    "        \n",
    "        self.doc = open('{}.txt'.format(name), encoding='utf-8').read().strip().split(' ')\n",
    "        self.len = len(self.doc)\n",
    "        self.addWord()\n",
    "    \n",
    "    def addWord(self):\n",
    "        for word in self.doc:\n",
    "            if word not in self.word2idx:\n",
    "                self.word2idx[word] = self.n_words\n",
    "                self.word2count[word] = 1\n",
    "                self.idx2word[self.n_words] = word\n",
    "                self.n_words += 1\n",
    "            else:\n",
    "                self.word2count[word] += 1\n",
    "    \n",
    "    def term_freq(self, term): # doc 에서 term이 몇번이나 나왔는지.\n",
    "        if term not in self.word2idx:\n",
    "            return 0\n",
    "        return self.word2count[term]\n",
    "        \n",
    "    def tf_weight(self, term):\n",
    "        if self.term_freq(term) > 0:\n",
    "            return 1 + math.log10(self.term_freq(term))\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "class query_processor(object):\n",
    "    \n",
    "    def __init__(self, query):\n",
    "        \n",
    "        self.word2idx = {}\n",
    "        self.idx2word = {}\n",
    "        self.word2count = {}\n",
    "        self.n_words = 0\n",
    "        \n",
    "        self.doc = query\n",
    "        self.len = len(self.doc)\n",
    "        self.addWord()\n",
    "    \n",
    "    def addWord(self):\n",
    "        for word in self.doc:\n",
    "            if word not in self.word2idx:\n",
    "                self.word2idx[word] = self.n_words\n",
    "                self.word2count[word] = 1\n",
    "                self.idx2word[self.n_words] = word\n",
    "                self.n_words += 1\n",
    "            else:\n",
    "                self.word2count[word] += 1\n",
    "    \n",
    "    def term_freq(self, term): # doc 에서 term이 몇번이나 나왔는지.\n",
    "        if term not in self.word2idx:\n",
    "            return 0\n",
    "        return self.word2count[term]\n",
    "        \n",
    "    def tf_weight(self, term):\n",
    "        if self.term_freq(term) > 0:\n",
    "            return 1 + math.log10(self.term_freq(term))\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "def doc_freq(term, docs):\n",
    "    ret = 0\n",
    "    for doc in docs:\n",
    "        if doc.term_freq(term) != 0:\n",
    "            ret += 1\n",
    "    return ret\n",
    "\n",
    "def idf_weight(term, docs):\n",
    "    return math.log10(1.0 * len(docs) / 1.0 * doc_freq(term, docs))\n",
    "\n",
    "def tf_idf_weight(doc, term, docs):\n",
    "    return doc.tf_weight(term) * idf_weight(term, docs)\n",
    "\n",
    "    \n",
    "def score_for_given_query(query, docs):\n",
    "    score = {}\n",
    "    for i in range(len(docs)):\n",
    "        for term in query:\n",
    "            if 'doc{}'.format(i+1) not in score:\n",
    "                score['doc{}'.format(i+1)] = tf_idf_weight(docs[i], term, docs)\n",
    "            else:\n",
    "                score['doc{}'.format(i+1)] += tf_idf_weight(docs[i], term, docs)\n",
    "    \n",
    "    return score\n",
    "\n",
    "def cosine_score(query, query_, docs):\n",
    "    \n",
    "    score = {}\n",
    "    \n",
    "    for i in range(len(docs)):\n",
    "        for term in query:\n",
    "            if 'doc{}'.format(i+1) not in score:\n",
    "                score['doc{}'.format(i+1)] = tf_idf_weight(docs[i], term, docs) * (query_.tf_weight(term))\n",
    "            else:\n",
    "                score['doc{}'.format(i+1)] += tf_idf_weight(docs[i], term, docs) * (query_.tf_weight(term))\n",
    "    \n",
    "    for i in range(0,len(docs)):\n",
    "        score['doc{}'.format(i+1)] /= 1.0 * docs[i].__len__()\n",
    "        \n",
    "    score = sorted(score.items(), key = operator.itemgetter(1), reverse = True)\n",
    "    \n",
    "    return score\n",
    "\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "\n",
    "# using animal names for making docs and queries\n",
    "animals = [\"salmon\", \"tiger\", \"ant\", \"deer\", \"human\", \"fish\", 'dog', 'cat', 'spider', 'rook', 'ram', 'raccoon', 'lark', 'hummingbird', 'gorilla', 'shark', 'whale', 'weasel', 'wolf', 'wren', 'yak', 'cow']\n",
    "\n",
    "\n",
    "# In[6]:\n",
    "\n",
    "\n",
    "# make 10 docs which consists of random 60 animals\n",
    "for i in range(1,11):\n",
    "    f = open('doc{}.txt'.format(i), 'w')\n",
    "    random.seed(i*7)\n",
    "    for k in range(0,60):\n",
    "        f.write(unicode(animals[random.randrange(0,len(animals))] + ' '))\n",
    "    f.close()\n",
    "\n",
    "# pre-processing 10 docs\n",
    "docs = []\n",
    "for i in range(1,11):\n",
    "    docs.append(doc_processor('doc{}'.format(i)))\n",
    "    print('Pre-processed {}...'.format('doc{}'.format(i)))\n",
    "\n",
    "\n",
    "# In[9]:\n",
    "\n",
    "\n",
    "print('Start Testing...\\n')\n",
    "\n",
    "for i in range(5):\n",
    "    print('\\n############## Test{} ###############\\n'.format(i+1))\n",
    "    random.seed(i*3)\n",
    "    \n",
    "    #make random query(animal names)\n",
    "    query = []\n",
    "    \n",
    "    for _ in range(5):\n",
    "        query.append(animals[random.randrange(0,len(animals))])\n",
    "    query_ = query_processor(query)\n",
    "        \n",
    "    print('Query : ', query,'\\n')\n",
    "    print('Compute tf.idf scores...\\n')\n",
    "    \n",
    "    tfidf = score_for_given_query(query,docs)\n",
    "    tfidf = sorted(tfidf.items(), key = operator.itemgetter(1), reverse = True)\n",
    "    \n",
    "    for k in range(1,6):\n",
    "        print('Top{} : {}'.format(k, tfidf[k-1]))\n",
    "        \n",
    "    print('\\nCompute cosine scores...\\n')\n",
    "    \n",
    "    cosine_scr = cosine_score(query, query_, docs)\n",
    "    \n",
    "    for k in range(1,6):\n",
    "        print('Top{} : {}'.format(k, cosine_scr[k-1]))\n",
    "        \n",
    "print('\\n\\nAll of tests are finished !!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
