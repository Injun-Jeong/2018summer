linear regression을 tensorflow 모델을 사용하여 구현해볼 것임



hypothesis & cost function
- H(x) = Wx + b
  W: weight
  b: bias
[code]
hypothesis = x_train * W + b		// hypothesis node



tensorflow mechanism
- 우선 graph를 build하고
- session을 통해 build한 graph를 run



tf.Variable
- 주어진 예시들에 대하여 W와 b의 값을 정의하여야 하는데, 이를 tensorflow에서는 Varialbe이란 node로 정의할 수 있음
- 여기서 variable이란 개념은 'tensorflow를 실행시키면 tensorflow가 자체적으로 변경시키는 값' 이라는 의미
- trainable이라고도 불림
- W와 b의 값을 모르니, random_normal로 설정하면서 shape을 값이 하나인 1차원 array(tensor)인 [1]로 정의
[code]
W = tf.Variable(tf.random_normal([1]), name = 'weight')
b = tf.Variable(tf.random_normal([1]), name = 'bias')



tf.square & tf.reduce_mean
- 제곱과 평균 값을 구해주는 tensorflow code



minimize cost
- tensorflow에는 minimize cost를 만족시키는 W와 b를 구하는데 여러가지 방법이 있음
- 그 중에 하나인 gradient descent를 사용할 것임
- gradient descent를 사용할 땐, tf.train.GradientDescentOptimizer
- 아래의 코드가 매우 중요함
[code]
optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.01)
train = optimizer.minimize(cost)



Variable node
- tf.Variable을 만들었을 때, variable node를 사용하기 위해서는 반드시 sess.run(tf.global_variables_initializer()) 을 명령해주어야 함










